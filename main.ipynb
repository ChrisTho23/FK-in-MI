{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATS Application - Christophe Thomassin: <br> Factual Knowledge in Transformer Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I am gonna try to back-up my code with some comments for better understandanding as time allows. Although I want to refer to the Google Docs document for an in-depth analysis: [Link](https://docs.google.com/document/d/13CZcQ818lBNqBGEqn3wxq3iVc7uHldprSr2tgTrBUr8/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Task**: <br>\n",
    "I am interested in understanding how Transformer Language Model store and retrieve knowledge, to be specific factual knowledge. Factual knowledge is essential to all possible information processing tasks as it can be considered the underlying assumptions of pretty much every step of reasoning. So, if LLMs were not able to acquire factual knowledge, they would be not much more than random word generators. I have three reasons why I think applying MI to understand how LLMs acquire and store factual knowledge is a good idea:\n",
    "1. I see facutal knowledge as the easiest form of intelligence, the entry point to cognitive capabilities. Hence, I find it intuitive to start with examining factual knowledge when trying \"mechanistically\" unwined the complexity of LLMs. Once understood, factual knowledge will open a lot of doors to dig deeper into the \"mind\" of Transformers.\n",
    "2. Factual knowledge, or in this case the lack of it, can be considered a large driver of Hallucinations. Understanding how and where factual knowledge is stored could allow us to remediate many Hallucinations.\n",
    "3. Factual knowledge, as the name indicates, is based on commonly-known facts which makes it quite easy to evaluate factual knowledge (one would think). A fact can only be True or False.\n",
    "\n",
    "One of the main drawbacks is that, as one could imagine, we cannot expect factual knowledge to be \"universal\". En contraire, because of its factual nature it is most definitely highly dependent of the training data. A model cannot reason that Paris is the capital of France, without being told that it is during pre-training. Hence, we might see that some models have developed specific factual knowledge while others have not. Yet, my hope is that the mechanisims allowing to store and retrieve factual knowledge are somewhat universal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows to reload packages when reimported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformer_lens.utils as utils\n",
    "from dotenv import load_dotenv\n",
    "from fancy_einsum import einsum\n",
    "from huggingface_hub import login\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from src.config import DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/chrisoutho_gmail_com/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device: torch.device = utils.get_device()\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   question  answer\n",
      "0         Is Paris the capital of France?\\n    True\n",
      "1   Is the Eiffel Tower located in Paris?\\n    True\n",
      "2    Is Paris known as the City of Light?\\n    True\n",
      "3               Is Paris a city in Italy?\\n   False\n",
      "4  Is the Louvre Museum located in Paris?\\n    True\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(DATA / \"fk_samples.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True': ['Yes', 'Sure', 'Correct', 'Certainly', 'Absolutely', 'Indeed', 'True', 'Yep'], 'False': ['No', 'no', 'Nope', ' No', ' no', 'Wrong', 'NO', 'False']}\n"
     ]
    }
   ],
   "source": [
    "with open(DATA / \"answer_map.json\", \"r\") as f:\n",
    "    answer_map = json.load(f)\n",
    "\n",
    "print(answer_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd95e677667a4144958107bfc8f78437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 06:29:25,600 - root - WARNING - You are not using LayerNorm, so the writing weights can't be centered! Skipping\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2b-it into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"google/gemma-2b-it\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logit_diff import df_to_logits\n",
    "\n",
    "logits, cache = df_to_logits(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import answer_map_to_tokens\n",
    "\n",
    "answer_map_tokens = answer_map_to_tokens(model, answer_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, we want to understand how the model stores and retrieves factual knowledge. To do so, as in every MI investigation, we have to define a task that allows us to evaluate LLM's on our task, factual knowledge. There are a few things to consider when engineering this task:\n",
    "1. Most importantly: We want to isolate the concept we are testing for, here, factual knowledge, as much as possible. Good performance on our task should imply that the tasked model is good at the exact concept we are interested in. Conversly, if a model does not perform good on our task, this should imply this model is not good at this concept.\n",
    "2. Our generation should only be one token long for easy evaluation. It would be nice if one could determine another token that would be expected if the model were not able to correctly answer the query. These two tokens can be used for introducing logit difference as evaluation metric to the task.\n",
    "3. It should be easy to scale the task to many different examples to rule out randomness.\n",
    "4. It should be possible, only by changing a few tokens, to remove the concept from the task and make it random. This alternative distributions is needed for path patching and ablation.\n",
    "\n",
    "For this time-constrained assessment, I will have to focus on a specific example. I chose to inspect factual knowledge around the French city \"Paris\". Paris is well-known enough to be in pretty much every pre-training dataset, yet yields enough diversity to ask mutiple questions in order to prove generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under consideration of all these requirements, I selected a question-answer format for factual knowledge as task. This allows to isolate specific factual knowledge, yields one-token generations, scales pefectly, and makes it possible to \"disarm\" the query by removing the \"key\".\n",
    "\n",
    "An example, which I will use a lot throughout this assessment, is: <br>\n",
    "    - Query: Is Paris the capital of France? <br>\n",
    "    - Label: True <br>\n",
    "    - Opposite Generation: False <br>\n",
    "    - Clue: capital, France <br>\n",
    "\n",
    "I admit that this task has the drawback that I am quite sure that question-answering is a unique circuit worth studying by itself. I expect the question-answering circuits and the factual knowledge circuit to have an overlap which means I did not 100% isolate our concept. Nonetheless, after a lot of back-and-forth, I believe this is the best way of testing factual knowledge for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the model is able to confidently solve this task in the first place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Is Paris the capital of France?\\n\"\n",
    "ground_truth = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Note</summary>\n",
    "It seems like I have to add the '\\n' tokens at the end of the query for this model to answer properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'Is', ' Paris', ' the', ' capital', ' of', ' France', '?', '\\n']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.09</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35.34</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m32.09\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m35.34\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 32.54 Prob: 55.63% Token: |Sure|\n",
      "Top 1th token. Logit: 32.09 Prob: 35.34% Token: |Yes|\n",
      "Top 2th token. Logit: 29.96 Prob:  4.22% Token: |No|\n",
      "Top 3th token. Logit: 29.90 Prob:  3.96% Token: |Paris|\n",
      "Top 4th token. Logit: 26.54 Prob:  0.14% Token: |Answer|\n",
      "Top 5th token. Logit: 26.24 Prob:  0.10% Token: |Certainly|\n",
      "Top 6th token. Logit: 26.02 Prob:  0.08% Token: |The|\n",
      "Top 7th token. Logit: 25.92 Prob:  0.07% Token: |Of|\n",
      "Top 8th token. Logit: 25.76 Prob:  0.06% Token: |Correct|\n",
      "Top 9th token. Logit: 25.70 Prob:  0.06% Token: |*|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.test_prompt(query, ground_truth, model, prepend_bos=True, prepend_space_to_answer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this looks good, we see the first \"inconvenience\" in our task here. The model is more than capable of answering the query. Yet, it is not able to concentrate all its probability mass on one \"True-token\" such as \"Yes\" but spreads it among multiple such as \"Sure\" (56% probability), \"Yes\" (35% probability), and \"Certainly\" (0.1% probability). This is most likely because assertion of something being true is most definitely done by using all these words in the training data. While this does not make the generation wrong, it raises two questions:\n",
    "1. Is the model abel to understand that all these tokens express \"True\" and build a circuit out of that?\n",
    "2. How do we evaluate the task if we cannot measure it's outcome based on the logit/probability of a single token?\n",
    "\n",
    "For the first question, I do not have a concrete answer but, for the sake of this experiment, I will just hope that the model chosen here is indeed able to abstract the answers into \"Fact is True\" and \"Fact is False\". Larger models such as ChatGPT 4o are definitely able to do so. This model achieved close to 100% accuracy on 10 simple factual knowledge questions around Paris under the condition of answering with True or False only. For the second question, we will have to find a solution to capture all possible True- and False-tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through a bunch of example questions, I have mapped all True- and Wrong-Tokens to their corresponding underlying meaning. Although, computationally, it is not very elegant (especially bc lists have diff lenghts), we will have to always evalaute the task on all these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True': ['Yes',\n",
       "  'Sure',\n",
       "  'Correct',\n",
       "  'Certainly',\n",
       "  'Absolutely',\n",
       "  'Indeed',\n",
       "  'True',\n",
       "  'Yep'],\n",
       " 'False': ['No', 'no', 'Nope', ' No', ' no', 'Wrong', 'NO', 'False']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the question is, can we still use logit difference to quantify the probability mass conentrated on each answer if we consider groups of tokens? When comparing logits of two tokens (say $diff = logit_1 - logit_2$), we know that the token with the higher logit will have a $e^{diff}$ higher token probability. For groups of tokens this is not so straightforward because the softmax is not a linear operator. Yet, under certain assumptions, the logit difference also has value for comparing probability mass assigned to groups of tokens. Let's do a little back of envelope calculation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say $T$ is the set of tokens describing True and $W$ is the set of tokens describing wrong. Furthermore, let's assume $|T| = |W| = n$. $U$ is the set of all tokens in the vocabulary.\n",
    "\n",
    "The difference $diff$ we are now computing is $\\text{diff} = \\sum_{i \\in T} \\text{logit}_i - \\sum_{j \\in W} \\text{logit}_j = n \\left( \\overline{\\text{logit}_T} - \\overline{\\text{logit}_W} \\right)$\n",
    "\n",
    "We can express the token probability of all True-tokens as: $p_T = \\frac{\\sum_{i \\in T} e^{\\text{logit}_i}}{\\sum_{u \\in U} e^{\\text{logit}_u}} = \\frac{e^{\\overline{\\text{logit}_T}} \\cdot \\sum_{i \\in T} e^{\\Delta_i}}{\\sum_{u \\in U} e^{\\text{logit}_u}}$ where $\\Delta_i$ is the difference of logit of token i and the average logit of all True-tokens\n",
    "\n",
    "Equivalently, we can express the token probability of all Wrong-tokens as: $p_W = \\frac{\\sum_{j \\in W} e^{\\text{logit}_j}}{\\sum_{u \\in U} e^{\\text{logit}_u}} = \\frac{e^{\\overline{\\text{logit}_W}} \\cdot \\sum_{j \\in W} e^{\\Delta_j}}{\\sum_{u \\in U} e^{\\text{logit}_u}}$ where $\\Delta_j$ is the difference of logit of token j and the average logit of all Wrong-tokens\n",
    "\n",
    "Hence, the probability of True-tokens is a multiple of the probability of Wrong-tokens of magnitude: $\\frac{p_T}{p_W} = \\frac{\\sum_{i \\in T} e^{\\text{logit}_i}}{\\sum_{j \\in W} e^{\\text{logit}_j}} = e^{\\frac{\\overline{\\text{logit}_T}}{\\overline{\\text{logit}_W}}} \\cdot \\frac{\\sum_{i \\in T} e^{\\Delta_i}}{\\sum_{j \\in W} e^{\\Delta_j}} = e^{\\frac{\\text{diff}}{n}} \\cdot \\frac{\\sum_{i \\in T} e^{\\Delta_i}}{\\sum_{j \\in W} e^{\\Delta_j}} \\approx e^{\\frac{\\text{diff}}{n}}$ \n",
    "\n",
    "Assuming: $\\frac{\\sum_{i \\in T} e^{\\Delta_i}}{\\sum_{j \\in W} e^{\\Delta_j}} \\approx 1 \\quad$ i.e., logits of tokens in W and T follow similar distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, assuming we have a similar token distribution, we can use the average logit difference $\\frac{\\text{diff}}{n}$ to quantify the difference in token probability of the two groups. Let's try out this new metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'question': [query], 'answer': [True]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit difference of True and False tokens summed up is 4.99 nats\n"
     ]
    }
   ],
   "source": [
    "from src.logit_diff import logits_to_logit_diff\n",
    "\n",
    "logits, cache = df_to_logits(model, df)\n",
    "logit_diff = logits_to_logit_diff(df, logits, answer_map_tokens, device)\n",
    "print(f\"Logit difference of True and False tokens summed up is {logit_diff:.2f} nats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When accounting for all True and False token, the model is clearly able to classifiy the statement as True. The True-token have an $e^{5}\\approx 148\\times$ higher probability than the False-token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more example testing factual knowledge around Paris to make sure our results are representative. I will use OpenAI's ChatGPT-4o for dataset generation and subsequently filter to only include valid examples. This might seem unnecessary for our experiment since there are not too many qeustion-answer pairs around Paris such a small model can answer but I this makes it easy to adapt this script to other use-cases in the future and most of the code is simply recycled..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-2024-08-06\"\n",
    "query = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"Please generate 10 questions about Paris that can be answered with \"\n",
    "            \"either Yes or No. Annotate each question with True if the answer is \"\n",
    "            \"Yes and False if the answer is No. The questions should be easy to \"\n",
    "            \"answer for any human. Return the output as a JSON object with each \"\n",
    "            \"entry having the keys 'question' and 'answer' filled with a list of \"\n",
    "            \"10 values. There should be 5 questions with answer Yes and 5 \"\n",
    "            \"questions with answer no. Each question should end with a question \"\n",
    "            \"mark followed by the newline character.\\n\"\n",
    "            \"Example question: Is Paris the capital of France?\\n\"\n",
    "            \"Example answer: True\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ClientResponse(https://api.openai.com/v1/chat/completions) [200 OK]>\n",
      "<CIMultiDictProxy('Date': 'Thu, 29 Aug 2024 07:09:58 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Access-Control-Expose-Headers': 'X-Request-ID', 'openai-organization': 'christho', 'openai-processing-ms': '7052', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '29839', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '322ms', 'x-request-id': 'req_fffa1c3be4c49c140382a4b5b1e3aa50', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=a9h9e12B1G53GbGInmzNYNdWo0LLdwRqhz2K_Ttm6cY-1724915398-1.0.1.1-xKOd.eHUEp8Po9qjv_ethFtrkAIOTGssNBKerF1Yl4s2UGu6KbXyFUuz_v6RLoQYqskOZ7VwGqFyYnlzf6YqNQ; path=/; expires=Thu, 29-Aug-24 07:39:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'X-Content-Type-Options': 'nosniff', 'Set-Cookie': '_cfuvid=HxQYDneomowyaDQ1NB6UvWAxHJnpi3Jv98NvDw9HdrI-1724915398309-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '8baab7c9dbc01058-ORD', 'Content-Encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400')>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from src.data import invoke_openai\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dataset = asyncio.run(invoke_openai(model_name, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset[0])\n",
    "df[\"answer\"] = df[\"answer\"].apply(lambda x: True if x == \"True\" else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd364 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fd364_row0_col0, #T_fd364_row0_col1, #T_fd364_row1_col0, #T_fd364_row1_col1, #T_fd364_row2_col0, #T_fd364_row2_col1, #T_fd364_row3_col0, #T_fd364_row3_col1, #T_fd364_row4_col0, #T_fd364_row4_col1, #T_fd364_row5_col0, #T_fd364_row5_col1, #T_fd364_row6_col0, #T_fd364_row6_col1, #T_fd364_row7_col0, #T_fd364_row7_col1, #T_fd364_row8_col0, #T_fd364_row8_col1, #T_fd364_row9_col0, #T_fd364_row9_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd364\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd364_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_fd364_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd364_row0_col0\" class=\"data row0 col0\" >Is the Eiffel Tower located in Paris?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row0_col1\" class=\"data row0 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fd364_row1_col0\" class=\"data row1 col0\" >Is Paris the largest city in Germany?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row1_col1\" class=\"data row1 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fd364_row2_col0\" class=\"data row2 col0\" >Does the Louvre Museum reside in Paris?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fd364_row3_col0\" class=\"data row3 col0\" >Is Paris known as the City of Love?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row3_col1\" class=\"data row3 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fd364_row4_col0\" class=\"data row4 col0\" >Is Paris situated on the banks of the Thames River?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row4_col1\" class=\"data row4 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fd364_row5_col0\" class=\"data row5 col0\" >Can you find the Notre-Dame Cathedral in Paris?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_fd364_row6_col0\" class=\"data row6 col0\" >Is Paris famous for its sushi?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_fd364_row7_col0\" class=\"data row7 col0\" >Does Paris have more than 10 million residents?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row7_col1\" class=\"data row7 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_fd364_row8_col0\" class=\"data row8 col0\" >Is the Arc de Triomphe a famous monument in Paris?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd364_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_fd364_row9_col0\" class=\"data row9 col0\" >Is the official language of Paris Spanish?\n",
       "</td>\n",
       "      <td id=\"T_fd364_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f01cf2c1c90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10).style.set_properties(**{'text-align': 'left'}).set_table_styles([dict(selector='th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's make sure our model is able to answer all questions correctly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = df_to_logits(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per prompt logit difference: tensor([ 3.5940,  2.3680,  8.9890,  5.6400,  4.4280, -1.1900,  5.2440,  3.6440,\n",
      "         6.0260,  0.8290])\n",
      "Average logit difference: tensor(3.9600)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Per prompt logit difference:\",\n",
    "    logits_to_logit_diff(df, logits, answer_map_tokens, device, per_prompt=True)\n",
    "    .cpu()\n",
    "    .round(decimals=3),\n",
    ")\n",
    "print(\n",
    "    \"Average logit difference:\",\n",
    "    logits_to_logit_diff(df, logits, answer_map_tokens, device)\n",
    "    .clone()\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .round(decimals=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we see that overall the model is more than able to assign higher probability to True-tokens (avg. logit difference is around 4 nats). But for two samples (index 5 and 9) we get a negative/close-to-negative logit difference. Let's have a look what's happening there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'Is', ' Paris', ' the', ' largest', ' city', ' in', ' Europe', '?', '\\n']\n",
      "Tokenized answer: ['False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.79</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">False</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m37\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m22.79\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;3;91mFalse\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 33.59 Prob: 51.47% Token: |No|\n",
      "Top 1th token. Logit: 33.06 Prob: 30.36% Token: |Sure|\n",
      "Top 2th token. Logit: 32.00 Prob: 10.51% Token: |Yes|\n",
      "Top 3th token. Logit: 31.54 Prob:  6.59% Token: |Paris|\n",
      "Top 4th token. Logit: 29.14 Prob:  0.60% Token: |The|\n",
      "Top 5th token. Logit: 27.78 Prob:  0.15% Token: |no|\n",
      "Top 6th token. Logit: 27.13 Prob:  0.08% Token: |True|\n",
      "Top 7th token. Logit: 26.55 Prob:  0.04% Token: | Paris|\n",
      "Top 8th token. Logit: 26.11 Prob:  0.03% Token: |Answer|\n",
      "Top 9th token. Logit: 25.99 Prob:  0.03% Token: |Certainly|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'False'\u001b[0m, \u001b[1;36m37\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'Is', ' Paris', ' home', ' to', ' the', ' Co', 'losseum', '?', '\\n']\n",
      "Tokenized answer: ['False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.92</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">False</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m33\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m22.92\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;3;91mFalse\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 35.45 Prob: 95.16% Token: |No|\n",
      "Top 1th token. Logit: 31.36 Prob:  1.59% Token: |The|\n",
      "Top 2th token. Logit: 31.13 Prob:  1.26% Token: |Sure|\n",
      "Top 3th token. Logit: 30.85 Prob:  0.95% Token: |Paris|\n",
      "Top 4th token. Logit: 30.60 Prob:  0.74% Token: |Yes|\n",
      "Top 5th token. Logit: 29.13 Prob:  0.17% Token: |no|\n",
      "Top 6th token. Logit: 27.59 Prob:  0.04% Token: |There|\n",
      "Top 7th token. Logit: 26.73 Prob:  0.02% Token: | No|\n",
      "Top 8th token. Logit: 26.23 Prob:  0.01% Token: | no|\n",
      "Top 9th token. Logit: 26.04 Prob:  0.01% Token: |Answer|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'False'\u001b[0m, \u001b[1;36m33\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [5, 9]:\n",
    "    utils.test_prompt(df[\"question\"].iloc[i], str(df[\"answer\"].iloc[i]), model, prepend_bos=True, prepend_space_to_answer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first sample, the model actually does not seem to be able to answer our question with high confidence (token probability of 'No' about the same as of True token). We should probably get rid of this sample. Yet, we noitice that the difference in token probability in this case is still postive. Why do we get a negative average logit difference? For the second sample, we actually get a 95.2% token probability for the False-token 'No', yet the logit difference is barely positive. Why is that? Well in these two cases the previously described condition of similar logit distribution for both token groups is not fulfilled. In the latter case we have a much larger variance in Wrong-token than in True-token which makes us underestimate the actual multiple in token probability. This is a clear problem with our method. An alternative solution could be to use token probability for comparison. Let's add this as a feature to our logits_to_logits_diff method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logit_diff import logits_to_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per prompt logit difference: tensor([0.5940, 0.2050, 0.8950, 0.9940, 0.8270, 0.4090, 0.7470, 0.9880, 0.8480,\n",
      "        0.8900])\n",
      "Average logit difference: tensor(0.7400)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Per prompt logit difference:\",\n",
    "    logits_to_logit_diff(df, logits, answer_map_tokens, device, return_probs=True, per_prompt=True)\n",
    "    .cpu()\n",
    "    .round(decimals=3),\n",
    ")\n",
    "print(\n",
    "    \"Average logit difference:\",\n",
    "    logits_to_logit_diff(df, logits, answer_map_tokens, device, return_probs=True)\n",
    "    .clone()\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .round(decimals=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks way better. Now we have found two insightful metric to evaluate our task. Let's still remove the sample with index 5 from the dataframe as the model seems to be unsure about this case and move on to the fun part..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = [5]\n",
    "df.drop(drop_idx, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset:\n",
      "                                          question  answer\n",
      "0                Is Paris the capital of France?\\n    True\n",
      "1          Is the Eiffel Tower located in Paris?\\n    True\n",
      "2           Is Paris known as the City of Light?\\n    True\n",
      "3                      Is Paris a city in Italy?\\n   False\n",
      "4         Is the Louvre Museum located in Paris?\\n    True\n",
      "5        Does the Seine River run through Paris?\\n    True\n",
      "6  Is Paris situated on the Mediterranean coast?\\n   False\n",
      "7         Is the Arc de Triomphe found in Paris?\\n    True\n",
      "8                Is Paris home to the Colosseum?\\n   False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final dataset:\\n{df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA / 'fk_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Logit Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of direct logit attribution is to quantify how the different components in our transformer affect the outcome of our task. When evaluationg the token probability of only two tokens, $t_1$ and $t_2$, we can use the residual stream direction of our logit difference and observe how the vector product between this vector and the embedding of the final token in the residual stream behaves, layer by layer. A positive number indicates that the logit difference is high and vice versa. This works since unembedding $W_U$ and layernorm (normalization plus scaling), the two transformations applied to the final state of the residual stream are approxamately linear, and thus, we can expedite the evaluation step to the final residual stream embeddings.\n",
    "$$\n",
    "\\text{We are interested in the logit difference } diff = \\text{logits}_{t_1} - \\text{logits}_{t_2}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{We have unembedding matrix }W_u \\in \\mathbb{R}^{n_{\\text{vocab}}, d_{\\text{model}}} \\text{ and residual stream embedding } x_n \\in \\mathbb{R}^{d_{\\text{model}}, 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{logits} = \\text{Layernorm}\\left(W_u \\cdot x_n\\right) = \\gamma \\cdot \\text{Norm}(W_u \\cdot x_n) + \\beta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Hence, }\\text{logits}_{t_1} - \\text{logits}_{t_2} = \\gamma \\cdot \\text{Norm}\\left(W_U[t_1] \\cdot x_n\\right) + \\beta - \\gamma \\cdot \\text{Norm}\\left(W_U[t_2] \\cdot x_n\\right) + \\beta \\approx \\gamma \\cdot \\text{Norm}\\left((W_U[t_1] - W_U[t_2]) \\cdot x_n\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\propto (W_U[t_1] - W_U[t_2]) \\cdot x_n\n",
    "$$\n",
    "Now the question is, does this also work in our case of groups of tokens? The answer is two-fold. We have determined the average logit difference per group $diff_1 = \\frac{diff}{n} = \\frac{\\sum_{i \\in T} \\text{logits}_i - \\sum_{j \\in W} \\text{logits}_j}{n}$ and $diff_2 = \\sum_{i \\in T} p_i - \\sum_{j \\in W} p_j$ to be suitable metrics where metric one is slightly flawed by the assumption of similar logit distribution within the groups and equal size of the token groups. Unfortunately, \n",
    "quickly see that only this prior metric is of use for direct logit attribution. If the substitute $diff$ with $diff_1$ in the calculation above, we quickly see that can approximate $diff_1$ as follows $diff_1 \\propto \\frac{(\\sum_{i \\in T} W_U[t_i] - \\sum_{j \\in W} W_U[t_j]) \\cdot x_n}{n}$. Unfortunately, softmax, the final transformation applied to get to token probabilities, the evaluation metric we deemed most useful for our use-case, is not even close to being linear. Therefore, we cannot directly translate the a positive/negative change in direct logit attribution into an equal change in our second metric. Hence, we move forward with the first solution, bearing in mind the assumptions we have to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you deleted samples in the last section, rerun this cell\n",
    "from src.logit_diff import df_to_logits\n",
    "\n",
    "logits, cache = df_to_logits(model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the residual stream directiosn of our True-/False-Tokens. This means nothing else than that we retrieve the column-vectors in the unembedding matrix that will dictate the logit of the tokens we are interested in. We then sum those unembedding vector for the True- and False-Tokens respectively and substract the True-Token embeddings from the False-Token sum of unembeddings (or vice versa) according to our label. We end up with a logit_diff_direction vector for every sample in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.direct_logit_attribution import get_logit_diff_directions\n",
    "\n",
    "logit_diff_directions = get_logit_diff_directions(\n",
    "    model,\n",
    "    df,\n",
    "    answer_map_tokens,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the embedding of the residual stream for the last token in our sequence at every point in our network where the output of a layer is fed back into the residual stream to plot the value of the answer residual direction after each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "0_pre",
          "0_mid",
          "1_pre",
          "1_mid",
          "2_pre",
          "2_mid",
          "3_pre",
          "3_mid",
          "4_pre",
          "4_mid",
          "5_pre",
          "5_mid",
          "6_pre",
          "6_mid",
          "7_pre",
          "7_mid",
          "8_pre",
          "8_mid",
          "9_pre",
          "9_mid",
          "10_pre",
          "10_mid",
          "11_pre",
          "11_mid",
          "12_pre",
          "12_mid",
          "13_pre",
          "13_mid",
          "14_pre",
          "14_mid",
          "15_pre",
          "15_mid",
          "16_pre",
          "16_mid",
          "17_pre",
          "17_mid",
          "final_post"
         ],
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10,
          10.5,
          11,
          11.5,
          12,
          12.5,
          13,
          13.5,
          14,
          14.5,
          15,
          15.5,
          16,
          16.5,
          17,
          17.5,
          18
         ],
         "xaxis": "x",
         "y": [
          34.186527252197266,
          9.39217472076416,
          2.120885133743286,
          2.968532085418701,
          1.7250651121139526,
          0.8853050470352173,
          0.011322394013404846,
          -0.11229358613491058,
          -0.19439926743507385,
          -0.37895089387893677,
          -0.31407052278518677,
          -0.21287721395492554,
          -0.017242249101400375,
          -0.2885422706604004,
          -0.2986942529678345,
          -0.32036927342414856,
          -0.3175811767578125,
          -0.4079548418521881,
          -0.14834792912006378,
          -0.1556626409292221,
          -0.08893540501594543,
          -0.07309462130069733,
          0.1897696703672409,
          0.24458535015583038,
          0.8520089983940125,
          0.6332781910896301,
          0.8356340527534485,
          0.7921690940856934,
          2.542371988296509,
          2.4660961627960205,
          3.634436845779419,
          3.6397125720977783,
          4.854218006134033,
          4.773261547088623,
          5.237882137298584,
          5.802015781402588,
          4.529078006744385
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Accumulate Residual Stream"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"9640e54a-f7ca-47c7-880c-4dedfd286a82\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9640e54a-f7ca-47c7-880c-4dedfd286a82\")) {                    Plotly.newPlot(                        \"9640e54a-f7ca-47c7-880c-4dedfd286a82\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"0_pre\",\"0_mid\",\"1_pre\",\"1_mid\",\"2_pre\",\"2_mid\",\"3_pre\",\"3_mid\",\"4_pre\",\"4_mid\",\"5_pre\",\"5_mid\",\"6_pre\",\"6_mid\",\"7_pre\",\"7_mid\",\"8_pre\",\"8_mid\",\"9_pre\",\"9_mid\",\"10_pre\",\"10_mid\",\"11_pre\",\"11_mid\",\"12_pre\",\"12_mid\",\"13_pre\",\"13_mid\",\"14_pre\",\"14_mid\",\"15_pre\",\"15_mid\",\"16_pre\",\"16_mid\",\"17_pre\",\"17_mid\",\"final_post\"],\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0,5.5,6.0,6.5,7.0,7.5,8.0,8.5,9.0,9.5,10.0,10.5,11.0,11.5,12.0,12.5,13.0,13.5,14.0,14.5,15.0,15.5,16.0,16.5,17.0,17.5,18.0],\"xaxis\":\"x\",\"y\":[34.186527252197266,9.39217472076416,2.120885133743286,2.968532085418701,1.7250651121139526,0.8853050470352173,0.011322394013404846,-0.11229358613491058,-0.19439926743507385,-0.37895089387893677,-0.31407052278518677,-0.21287721395492554,-0.017242249101400375,-0.2885422706604004,-0.2986942529678345,-0.32036927342414856,-0.3175811767578125,-0.4079548418521881,-0.14834792912006378,-0.1556626409292221,-0.08893540501594543,-0.07309462130069733,0.1897696703672409,0.24458535015583038,0.8520089983940125,0.6332781910896301,0.8356340527534485,0.7921690940856934,2.542371988296509,2.4660961627960205,3.634436845779419,3.6397125720977783,4.854218006134033,4.773261547088623,5.237882137298584,5.802015781402588,4.529078006744385],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Logit Difference From Accumulate Residual Stream\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9640e54a-f7ca-47c7-880c-4dedfd286a82');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.direct_logit_attribution import residual_stack_to_logit_diff\n",
    "from src.utils import line\n",
    "\n",
    "tokens_per_group = len(answer_map[\"True\"])\n",
    "\n",
    "accumulated_residual, labels = cache.accumulated_resid(\n",
    "    layer=-1, incl_mid=True, pos_slice=-1, return_labels=True\n",
    ")\n",
    "logit_lens_logit_diffs = residual_stack_to_logit_diff(\n",
    "    accumulated_residual, \n",
    "    logit_diff_directions, \n",
    "    cache,\n",
    "    tokens_per_group\n",
    ")\n",
    "line(\n",
    "    logit_lens_logit_diffs,\n",
    "    x=np.arange(model.cfg.n_layers * 2 + 1) / 2,\n",
    "    hover_name=labels,\n",
    "    title=\"Logit Difference From Accumulate Residual Stream\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be completely honest, this is a rather unexpected result. We can see that we start with a very high average logit difference which dramatically decreases after the first self-attention layer. This is most likely random. The inital residual stream embedding of the last token is simply the embedding of that token itself, this token, the newline token ('\\n'), does not have any semantic meaning for the question. After this inital rapid decrease in layers 1-3, the average logit difference is somewhat constant around 0 until the MLP layer of layer 13 where it makes a jump to half of the final average logit difference. After the logit difference steadily continuous to increase until the final layer where a slight drop is recorded.\n",
    "<details><summary>Notes</summary>\n",
    "I have plotted this many times with many different samples. Unfortunately, there are little patterns to recognize hinting the task might be to vague. I mostly got a monotic increasting graph starting from a highly negative average logit difference to a positive average logit difference which intuitively made sense to me. Interestingly, there was always rapid increase in average logit difference after the MLP of layer 13. I will definitely try to make a deep dive into this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed increase in self-attention layer after layer 1: -0.55\n",
      "Summed increase in MLP layer after layer 1: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.direct_logit_attribution import increase_per_layer_type\n",
    "\n",
    "increase_per_layer_type(logit_lens_logit_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we neglect the first layer, we observe that the average logit difference increases much more in MLP layer than self-attention layer. Over the 17 remaining layer, the average logit difference in the residual stream decreases by -0.55 nat over self-attention layer and increases about 4.12 nat (92% of total increase) over MLP layer. This hints MLP layer a benefitial for this task although it is worth noting that layer often collaborate in circuits which limits the value of this isolated view. For instance, self-attention often encrypt information in residual stream subspaces which might be used by MLP layer to extract valuable information and write them to the residual stream themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the change in logit difference for each layer to confirm this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.direct_logit_attribution import get_logit_diff_directions\n",
    "\n",
    "logit_diff_directions = get_logit_diff_directions(\n",
    "    model,\n",
    "    df,\n",
    "    answer_map_tokens,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "embed",
          "0_attn_out",
          "0_mlp_out",
          "1_attn_out",
          "1_mlp_out",
          "2_attn_out",
          "2_mlp_out",
          "3_attn_out",
          "3_mlp_out",
          "4_attn_out",
          "4_mlp_out",
          "5_attn_out",
          "5_mlp_out",
          "6_attn_out",
          "6_mlp_out",
          "7_attn_out",
          "7_mlp_out",
          "8_attn_out",
          "8_mlp_out",
          "9_attn_out",
          "9_mlp_out",
          "10_attn_out",
          "10_mlp_out",
          "11_attn_out",
          "11_mlp_out",
          "12_attn_out",
          "12_mlp_out",
          "13_attn_out",
          "13_mlp_out",
          "14_attn_out",
          "14_mlp_out",
          "15_attn_out",
          "15_mlp_out",
          "16_attn_out",
          "16_mlp_out",
          "17_attn_out",
          "17_mlp_out"
         ],
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "xaxis": "x",
         "y": [
          34.186527252197266,
          -24.794353485107422,
          -7.271289348602295,
          0.8476474285125732,
          -1.2434673309326172,
          -0.8397596478462219,
          -0.873982846736908,
          -0.1236158236861229,
          -0.08210579305887222,
          -0.1845516562461853,
          0.06488046795129776,
          0.10119306296110153,
          0.1956351101398468,
          -0.27129995822906494,
          -0.010151737369596958,
          -0.02167530357837677,
          0.002787868259474635,
          -0.09037365019321442,
          0.25960686802864075,
          -0.007314689457416534,
          0.06672731786966324,
          0.015840739011764526,
          0.2628641128540039,
          0.054815832525491714,
          0.6074237823486328,
          -0.21873065829277039,
          0.20235569775104523,
          -0.043464694172143936,
          1.7502025365829468,
          -0.0762755498290062,
          1.168340802192688,
          0.005275209899991751,
          1.2145055532455444,
          -0.08095627278089523,
          0.4646207392215729,
          0.564132034778595,
          -1.2729367017745972
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Each Layer"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"28e5639b-5ea1-44af-b520-f1722d6abfec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"28e5639b-5ea1-44af-b520-f1722d6abfec\")) {                    Plotly.newPlot(                        \"28e5639b-5ea1-44af-b520-f1722d6abfec\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"embed\",\"0_attn_out\",\"0_mlp_out\",\"1_attn_out\",\"1_mlp_out\",\"2_attn_out\",\"2_mlp_out\",\"3_attn_out\",\"3_mlp_out\",\"4_attn_out\",\"4_mlp_out\",\"5_attn_out\",\"5_mlp_out\",\"6_attn_out\",\"6_mlp_out\",\"7_attn_out\",\"7_mlp_out\",\"8_attn_out\",\"8_mlp_out\",\"9_attn_out\",\"9_mlp_out\",\"10_attn_out\",\"10_mlp_out\",\"11_attn_out\",\"11_mlp_out\",\"12_attn_out\",\"12_mlp_out\",\"13_attn_out\",\"13_mlp_out\",\"14_attn_out\",\"14_mlp_out\",\"15_attn_out\",\"15_mlp_out\",\"16_attn_out\",\"16_mlp_out\",\"17_attn_out\",\"17_mlp_out\"],\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36],\"xaxis\":\"x\",\"y\":[34.186527252197266,-24.794353485107422,-7.271289348602295,0.8476474285125732,-1.2434673309326172,-0.8397596478462219,-0.873982846736908,-0.1236158236861229,-0.08210579305887222,-0.1845516562461853,0.06488046795129776,0.10119306296110153,0.1956351101398468,-0.27129995822906494,-0.010151737369596958,-0.02167530357837677,0.002787868259474635,-0.09037365019321442,0.25960686802864075,-0.007314689457416534,0.06672731786966324,0.015840739011764526,0.2628641128540039,0.054815832525491714,0.6074237823486328,-0.21873065829277039,0.20235569775104523,-0.043464694172143936,1.7502025365829468,-0.0762755498290062,1.168340802192688,0.005275209899991751,1.2145055532455444,-0.08095627278089523,0.4646207392215729,0.564132034778595,-1.2729367017745972],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Logit Difference From Each Layer\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('28e5639b-5ea1-44af-b520-f1722d6abfec');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.direct_logit_attribution import residual_stack_to_logit_diff\n",
    "from src.utils import line\n",
    "\n",
    "per_layer_residual, labels = cache.decompose_resid(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_layer_logit_diffs = residual_stack_to_logit_diff(\n",
    "    per_layer_residual, \n",
    "    logit_diff_directions, \n",
    "    cache,\n",
    "    tokens_per_group\n",
    ")\n",
    "line(per_layer_logit_diffs, hover_name=labels, title=\"Logit Difference From Each Layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed we see the largest change after the self-attention head in layer 1 after the MLP layer in layer 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's know decompose the output of attention layer in their single heads. This can be done by decomposing the output matrix into submatrices applied to the attention-scaled value output matrix of each head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Head: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           -2.812124490737915,
           -4.209907054901123,
           -1.576905608177185,
           -5.619256973266602,
           -4.991880416870117,
           -0.6085904836654663,
           -2.525470018386841,
           -2.4502155780792236
          ],
          [
           0.42778855562210083,
           -0.012315592728555202,
           0.5322874784469604,
           0.31328991055488586,
           -0.40544161200523376,
           -0.37399134039878845,
           0.06663063913583755,
           0.2993994355201721
          ],
          [
           -0.02778538689017296,
           -0.042967669665813446,
           -0.2308766096830368,
           -0.06929632276296616,
           -0.18037275969982147,
           -0.0896073505282402,
           -0.09727173298597336,
           -0.10158170759677887
          ],
          [
           -0.04853499308228493,
           -0.06011462211608887,
           0.025315815582871437,
           -0.04279075562953949,
           -0.036567289382219315,
           -0.09741374105215073,
           0.11795113235712051,
           0.018538692966103554
          ],
          [
           -0.005868460983037949,
           -0.02820635586977005,
           -0.037552885711193085,
           0.046942904591560364,
           -0.0032363932114094496,
           -0.09753374010324478,
           -0.03047637827694416,
           -0.02862032875418663
          ],
          [
           0.05660216137766838,
           -0.006133084185421467,
           -0.020179079845547676,
           0.030870629474520683,
           -0.013204513117671013,
           0.021899111568927765,
           0.008721730671823025,
           0.022616038098931313
          ],
          [
           -0.02055966481566429,
           -0.04338934272527695,
           0.017893120646476746,
           -0.10331341624259949,
           -0.03849531337618828,
           -0.01902531459927559,
           -0.038683537393808365,
           -0.025726327672600746
          ],
          [
           -0.03582822158932686,
           -0.0392250157892704,
           -0.027459075674414635,
           0.021556774154305458,
           0.007096141576766968,
           0.07360676676034927,
           -0.01610466279089451,
           -0.005318059120327234
          ],
          [
           -0.011227336712181568,
           -0.03108041174709797,
           -0.0025877461303025484,
           -0.012635000050067902,
           -0.012201239354908466,
           -0.018380293622612953,
           -0.0232287235558033,
           0.02096700109541416
          ],
          [
           0.006223306991159916,
           0.007437972817569971,
           -0.017496725544333458,
           0.03903732821345329,
           -0.0006961027975194156,
           -0.02550470270216465,
           -0.002926558256149292,
           -0.013389118947088718
          ],
          [
           -0.005076497793197632,
           0.027649128809571266,
           -0.02019203081727028,
           -0.00515410490334034,
           0.046639036387205124,
           -0.05024328455328941,
           -0.013362550176680088,
           0.0355810709297657
          ],
          [
           -0.008415956981480122,
           0.018071169033646584,
           -0.01820681244134903,
           -0.012946057133376598,
           -0.006942098494619131,
           0.012987993657588959,
           0.09448590129613876,
           -0.024218261241912842
          ],
          [
           -0.24059690535068512,
           -0.03507699817419052,
           0.0592900775372982,
           0.006162925623357296,
           0.04954884201288223,
           -0.08231022953987122,
           0.01455604750663042,
           0.00969565287232399
          ],
          [
           -0.04368329793214798,
           -0.044218726456165314,
           -0.018057439476251602,
           -0.013820230960845947,
           0.0965631976723671,
           0.0022074903827160597,
           -0.008240635506808758,
           -0.01421506516635418
          ],
          [
           -0.05121566727757454,
           0.0071478369645774364,
           0.00200182874687016,
           -0.01844935491681099,
           0.02020351029932499,
           -0.01489412784576416,
           0.000050519902288215235,
           -0.021120330318808556
          ],
          [
           -0.000822948117274791,
           0.03326180577278137,
           0.05014467611908913,
           -0.010393321514129639,
           -0.02285444736480713,
           -0.03710991144180298,
           -0.013103369623422623,
           0.006152724381536245
          ],
          [
           -0.0203520730137825,
           0.014921754598617554,
           -0.014974847435951233,
           -0.025041531771421432,
           -0.032174792140722275,
           -0.0002250903198728338,
           0.020543642342090607,
           -0.023653361946344376
          ],
          [
           0.47047773003578186,
           -0.06248040869832039,
           -0.09946361929178238,
           -0.1162891760468483,
           0.18845701217651367,
           -0.08980177342891693,
           0.3498375117778778,
           -0.07660546898841858
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Each Head"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"86bf6614-a198-434b-a6d8-c88d175011b6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"86bf6614-a198-434b-a6d8-c88d175011b6\")) {                    Plotly.newPlot(                        \"86bf6614-a198-434b-a6d8-c88d175011b6\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-2.812124490737915,-4.209907054901123,-1.576905608177185,-5.619256973266602,-4.991880416870117,-0.6085904836654663,-2.525470018386841,-2.4502155780792236],[0.42778855562210083,-0.012315592728555202,0.5322874784469604,0.31328991055488586,-0.40544161200523376,-0.37399134039878845,0.06663063913583755,0.2993994355201721],[-0.02778538689017296,-0.042967669665813446,-0.2308766096830368,-0.06929632276296616,-0.18037275969982147,-0.0896073505282402,-0.09727173298597336,-0.10158170759677887],[-0.04853499308228493,-0.06011462211608887,0.025315815582871437,-0.04279075562953949,-0.036567289382219315,-0.09741374105215073,0.11795113235712051,0.018538692966103554],[-0.005868460983037949,-0.02820635586977005,-0.037552885711193085,0.046942904591560364,-0.0032363932114094496,-0.09753374010324478,-0.03047637827694416,-0.02862032875418663],[0.05660216137766838,-0.006133084185421467,-0.020179079845547676,0.030870629474520683,-0.013204513117671013,0.021899111568927765,0.008721730671823025,0.022616038098931313],[-0.02055966481566429,-0.04338934272527695,0.017893120646476746,-0.10331341624259949,-0.03849531337618828,-0.01902531459927559,-0.038683537393808365,-0.025726327672600746],[-0.03582822158932686,-0.0392250157892704,-0.027459075674414635,0.021556774154305458,0.007096141576766968,0.07360676676034927,-0.01610466279089451,-0.005318059120327234],[-0.011227336712181568,-0.03108041174709797,-0.0025877461303025484,-0.012635000050067902,-0.012201239354908466,-0.018380293622612953,-0.0232287235558033,0.02096700109541416],[0.006223306991159916,0.007437972817569971,-0.017496725544333458,0.03903732821345329,-0.0006961027975194156,-0.02550470270216465,-0.002926558256149292,-0.013389118947088718],[-0.005076497793197632,0.027649128809571266,-0.02019203081727028,-0.00515410490334034,0.046639036387205124,-0.05024328455328941,-0.013362550176680088,0.0355810709297657],[-0.008415956981480122,0.018071169033646584,-0.01820681244134903,-0.012946057133376598,-0.006942098494619131,0.012987993657588959,0.09448590129613876,-0.024218261241912842],[-0.24059690535068512,-0.03507699817419052,0.0592900775372982,0.006162925623357296,0.04954884201288223,-0.08231022953987122,0.01455604750663042,0.00969565287232399],[-0.04368329793214798,-0.044218726456165314,-0.018057439476251602,-0.013820230960845947,0.0965631976723671,0.0022074903827160597,-0.008240635506808758,-0.01421506516635418],[-0.05121566727757454,0.0071478369645774364,0.00200182874687016,-0.01844935491681099,0.02020351029932499,-0.01489412784576416,5.0519902288215235e-05,-0.021120330318808556],[-0.000822948117274791,0.03326180577278137,0.05014467611908913,-0.010393321514129639,-0.02285444736480713,-0.03710991144180298,-0.013103369623422623,0.006152724381536245],[-0.0203520730137825,0.014921754598617554,-0.014974847435951233,-0.025041531771421432,-0.032174792140722275,-0.0002250903198728338,0.020543642342090607,-0.023653361946344376],[0.47047773003578186,-0.06248040869832039,-0.09946361929178238,-0.1162891760468483,0.18845701217651367,-0.08980177342891693,0.3498375117778778,-0.07660546898841858]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Logit Difference From Each Head\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('86bf6614-a198-434b-a6d8-c88d175011b6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.direct_logit_attribution import residual_stack_to_logit_diff\n",
    "from src.utils import imshow\n",
    "\n",
    "per_head_residual, labels = cache.stack_head_results(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(\n",
    "    per_head_residual, \n",
    "    logit_diff_directions, \n",
    "    cache,\n",
    "    tokens_per_group\n",
    ")\n",
    "per_head_logit_diffs = einops.rearrange(\n",
    "    per_head_logit_diffs,\n",
    "    \"(layer head_index) -> layer head_index\",\n",
    "    layer=model.cfg.n_layers,\n",
    "    head_index=model.cfg.n_heads,\n",
    ")\n",
    "imshow(\n",
    "    per_head_logit_diffs,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
    "    title=\"Logit Difference From Each Head\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = 1\n",
    "top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive_logit_attr_heads = torch.topk(\n",
    "    per_head_logit_diffs.flatten(), k=top_k\n",
    ").indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_negative_logit_attr_heads = torch.topk(\n",
    "    -per_head_logit_diffs.flatten(), k=top_k\n",
    ").indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='max-width: 700px;'><h2>Top 3 Positive Logit Attribution Heads</h2><br/><div id=\"circuits-vis-80c32361-b8c9\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-80c32361-b8c9\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2897569537162781, 0.7102430462837219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.052552543580532074, 0.27452966570854187, 0.6729177832603455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01110073085874319, 0.051969271153211594, 0.2714822292327881, 0.6654477715492249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005075304768979549, 0.01104442123323679, 0.051705531775951385, 0.27010416984558105, 0.6620705723762512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.4031251339474693e-05, 6.928758921276312e-06, 1.8768962036119774e-05, 0.0002280762855662033, 0.00362941506318748, 0.9961028099060059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014411931624636054, 0.0014388057170435786, 0.00180022232234478, 0.0030231690034270287, 0.005551597103476524, 0.6087655425071716, 0.37797948718070984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.164625948353205e-05, 3.171660500811413e-05, 4.534203253570013e-05, 8.930944022722542e-05, 0.00028400731389410794, 0.42672666907310486, 0.018658602610230446, 0.5541427135467529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004704996244981885, 0.0008077498059719801, 0.0010052825091406703, 0.001001344178803265, 0.0010977546917274594, 0.6399328708648682, 0.007935469038784504, 0.018515516072511673, 0.3292335867881775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.8729589757858776e-05, 6.452172965509817e-05, 0.00012620854249689728, 0.00018970230303239077, 0.00023607166076544672, 0.6591106057167053, 0.004440764430910349, 0.007261599879711866, 0.03034108318388462, 0.29820069670677185, 0.0, 0.0, 0.0, 0.0, 0.0], [1.5050868569232989e-05, 2.6984167561749928e-05, 6.169831613078713e-05, 0.00013619824312627316, 0.00023446162231266499, 0.3331681489944458, 0.002975349547341466, 0.008936998434364796, 0.018438678234815598, 0.6174293756484985, 0.018576961010694504, 0.0, 0.0, 0.0, 0.0], [9.510750533081591e-05, 0.00011307551176287234, 0.00019134642207063735, 0.00039518644916824996, 0.0007045464008115232, 0.5095479488372803, 0.020493824034929276, 0.024463580921292305, 0.018631529062986374, 0.1039196029305458, 0.03754163905978203, 0.2839025855064392, 0.0, 0.0, 0.0], [0.00036435533547773957, 0.0004127297434024513, 0.000531295663677156, 0.0007582593243569136, 0.0010998125653713942, 0.5440470576286316, 0.013650472275912762, 0.05071019381284714, 0.0058034202083945274, 0.10594819486141205, 0.1586305797100067, 0.010019437409937382, 0.10802412778139114, 0.0, 0.0], [0.00041583224083296955, 0.0004069217829965055, 0.0003962687333114445, 0.00043678449583239853, 0.0005546262254938483, 0.3747086524963379, 0.017713472247123718, 0.0309786144644022, 0.00477475905790925, 0.007437310181558132, 0.08797509968280792, 0.01932678557932377, 0.053821973502635956, 0.40105292201042175, 0.0], [0.00017615535762161016, 0.00019536283798515797, 0.00018262401863466948, 0.00016179792874027044, 0.0001621100673219189, 0.08267677575349808, 0.011863579973578453, 0.02869522012770176, 0.002381128491833806, 0.0029508983716368675, 0.03723719343543053, 0.0030002393759787083, 0.05815434455871582, 0.32065051794052124, 0.45151200890541077]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2538555860519409, 0.7461444139480591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018575532361865044, 0.24913963675498962, 0.7322847843170166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001479446073062718, 0.01854800432920456, 0.24877089262008667, 0.7312016487121582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004300609871279448, 0.0014788148691877723, 0.018540158867836, 0.2486647516489029, 0.7308862209320068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0031698259990662336, 0.001908438978716731, 0.0056330556981265545, 0.061948906630277634, 0.8036760091781616, 0.12366366386413574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003153574885800481, 0.0026072633918374777, 0.0034425100311636925, 0.013278939761221409, 0.10903783142566681, 0.6943972110748291, 0.17408262193202972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00011578073463169858, 0.00018022135191131383, 0.0002354500611545518, 0.0004856125160586089, 0.0024231933057308197, 0.5922859311103821, 0.12668608129024506, 0.2775877118110657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013484950177371502, 0.0022234302014112473, 0.0028223663102835417, 0.0032869509886950254, 0.005625780671834946, 0.28330597281455994, 0.1508396863937378, 0.4027180075645447, 0.14782936871051788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005012423498556018, 0.0010107515845447779, 0.0017235507257282734, 0.0021669010166078806, 0.002449874533340335, 0.1347821205854416, 0.06851210445165634, 0.10445552319288254, 0.08779752999544144, 0.596600353717804, 0.0, 0.0, 0.0, 0.0, 0.0], [9.082763426704332e-05, 0.00019022219930775464, 0.0005258980090729892, 0.0013410447863861918, 0.002576567465439439, 0.1099393367767334, 0.02990291826426983, 0.0415985994040966, 0.02299770526587963, 0.73943692445755, 0.05139988288283348, 0.0, 0.0, 0.0, 0.0], [0.00013501927605830133, 0.00020527528249658644, 0.0005664787604473531, 0.0020075237844139338, 0.004591955337673426, 0.08855291455984116, 0.012144641019403934, 0.04246923699975014, 0.004558378364890814, 0.18437734246253967, 0.5285047292709351, 0.1318865716457367, 0.0, 0.0, 0.0], [4.226729288347997e-05, 5.2204188250470906e-05, 8.130638889269903e-05, 0.00017760336049832404, 0.0004734208923764527, 0.05688493326306343, 0.006727212108671665, 0.020997976884245872, 0.0036811241880059242, 0.04038942605257034, 0.7963910102844238, 0.021649574860930443, 0.05245192348957062, 0.0, 0.0], [0.00024456658866256475, 0.00022865731443744153, 0.00018120877211913466, 0.0002027287264354527, 0.00040248577715829015, 0.10715126246213913, 0.007768852636218071, 0.008805354125797749, 0.002750737825408578, 0.003089524107053876, 0.07429135590791702, 0.028457386419177055, 0.3321601152420044, 0.43426579236984253, 0.0], [4.49380386271514e-05, 6.131042027845979e-05, 4.840086694457568e-05, 3.047066456929315e-05, 2.8932005079695955e-05, 0.015679899603128433, 0.0008742706850171089, 0.0010831581894308329, 0.0005391673184931278, 0.00023592152865603566, 0.005791046656668186, 0.00022463344794232398, 0.012625892646610737, 0.1900882124900818, 0.7726438045501709]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2491440773010254, 0.7508559226989746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05488115921616554, 0.23547090590000153, 0.7096479535102844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016669288277626038, 0.053966231644153595, 0.23154576122760773, 0.6978186964988708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010033979080617428, 0.01650202088057995, 0.053424715995788574, 0.2292221486568451, 0.6908170580863953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001120298053137958, 0.0007879034383222461, 0.002092335605993867, 0.015940219163894653, 0.12504324316978455, 0.8550160527229309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007881980389356613, 0.008953378535807133, 0.01180313155055046, 0.019656630232930183, 0.03506080061197281, 0.40249618887901306, 0.5141478776931763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002634661504998803, 0.00028484698850661516, 0.0004027112736366689, 0.0009645236423239112, 0.003423602320253849, 0.3904969096183777, 0.324799120426178, 0.27936482429504395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.3242540919454768e-05, 4.267417898518033e-05, 6.557607412105426e-05, 8.456211071461439e-05, 0.00013354752445593476, 0.033038172870874405, 0.11918754130601883, 0.5843893885612488, 0.26303529739379883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002501473936717957, 0.0003286456048954278, 0.00046234813635237515, 0.0006316073122434318, 0.0008912822231650352, 0.23302976787090302, 0.238125741481781, 0.1647706925868988, 0.184565931558609, 0.17694386839866638, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008466411381959915, 0.0009852118091657758, 0.0011283258209004998, 0.001291682943701744, 0.0016046863747760653, 0.12402406334877014, 0.3461209833621979, 0.40085840225219727, 0.023137716576457024, 0.0751173347234726, 0.024884996935725212, 0.0, 0.0, 0.0, 0.0], [0.0005909797619096935, 0.0007959728827700019, 0.0011848639696836472, 0.001821835176087916, 0.002617808058857918, 0.07918485254049301, 0.1993914693593979, 0.1994168609380722, 0.06074831262230873, 0.2705807387828827, 0.07376831024885178, 0.10989800095558167, 0.0, 0.0, 0.0], [0.0009102110052481294, 0.001104856957681477, 0.0015465464675799012, 0.0022723027504980564, 0.0029744410421699286, 0.10264477133750916, 0.06522224843502045, 0.16531553864479065, 0.00280669960193336, 0.05738893896341324, 0.5114344954490662, 0.013228191062808037, 0.07315070182085037, 0.0, 0.0], [0.0008717408054508269, 0.0008192883105948567, 0.0007757853018119931, 0.0008721279446035624, 0.0011513829231262207, 0.6054114103317261, 0.018479520455002785, 0.008830110542476177, 0.0036056337412446737, 0.0016188351437449455, 0.02020050585269928, 0.005376560613512993, 0.010306505486369133, 0.32168057560920715, 0.0], [0.00016021679039113224, 0.00015554044512100518, 0.00012798301759175956, 0.00011202762834727764, 0.00012557751324493438, 0.703263521194458, 0.0012190296547487378, 0.0009061867604032159, 0.0006314178463071585, 0.0002648864174261689, 0.0014487715670838952, 0.0005481005646288395, 0.0014243455370888114, 0.03984028846025467, 0.2497720718383789]]], \"attentionHeadNames\": [\"L17H6\", \"L17H0\", \"L17H4\"], \"tokens\": [\"<bos>\", \"Is\", \" Paris\", \" the\", \" largest\", \" city\", \" in\", \" Germany\", \"?\", \"\\n\"]}\n",
       "    )\n",
       "    </script></div><div style='max-width: 700px;'><h2>Top 3 Negative Logit Attribution Heads</h2><br/><div id=\"circuits-vis-44d4b972-bb47\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-44d4b972-bb47\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10338452458381653, 0.8966155052185059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010524090379476547, 0.10229673981666565, 0.8871791362762451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003006141632795334, 0.010492425411939621, 0.10198906809091568, 0.8845123648643494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0028687375597655773, 0.0029975161887705326, 0.010462344624102116, 0.10169655829668045, 0.8819749355316162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01505073718726635, 0.015435592271387577, 0.019379425793886185, 0.02883441001176834, 0.04386590048670769, 0.8774339556694031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007431182893924415, 0.0005868712905794382, 0.00032279492006637156, 0.00026399135822430253, 0.0006400354905053973, 0.1333988755941391, 0.8640443086624146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007805497734807432, 0.0011558952974155545, 0.0009760399698279798, 0.0005309173720888793, 0.0003985160728916526, 0.3517681956291199, 0.04672832787036896, 0.597661554813385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004508338402956724, 0.008273954503238201, 0.011474848724901676, 0.008460107259452343, 0.0041453223675489426, 0.4024839997291565, 0.014513205736875534, 0.01509090792387724, 0.5310493111610413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0021432701032608747, 0.0026064165867865086, 0.0036958546843379736, 0.00439187977463007, 0.0036627729423344135, 0.5287649631500244, 0.014740397222340107, 0.007601253222674131, 0.04085015505552292, 0.39154309034347534, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006754256784915924, 0.003362844465300441, 0.0028329496271908283, 0.004218724090605974, 0.006390912923961878, 0.14139334857463837, 0.015273084864020348, 0.002922654151916504, 0.00904096569865942, 0.05109471455216408, 0.7567154765129089, 0.0, 0.0, 0.0, 0.0], [0.008426152169704437, 0.005928193684667349, 0.003946223761886358, 0.003729425836354494, 0.005156824365258217, 0.29448121786117554, 0.0791252925992012, 0.022955363616347313, 0.0379985012114048, 0.048162106424570084, 0.013945150189101696, 0.47614553570747375, 0.0, 0.0, 0.0], [0.005104463081806898, 0.007028929423540831, 0.006025212351232767, 0.004614784847944975, 0.004523999057710171, 0.14883971214294434, 0.014270232059061527, 0.007984018884599209, 0.008410513401031494, 0.007306836079806089, 0.007903595454990864, 0.013262394815683365, 0.7647252678871155, 0.0, 0.0], [0.002141814911738038, 0.003941042814403772, 0.005188761744648218, 0.005047316197305918, 0.004891886841505766, 0.13645225763320923, 0.010459997691214085, 0.012864035554230213, 0.013774258084595203, 0.01372716948390007, 0.012472555041313171, 0.007725475821644068, 0.04940246418118477, 0.7219109535217285, 0.0], [0.0007545370608568192, 0.001355210319161415, 0.00239624478854239, 0.0029207179322838783, 0.0025370263028889894, 0.06254738569259644, 0.005963491275906563, 0.006370053626596928, 0.009441208094358444, 0.011131188832223415, 0.007262463215738535, 0.0045092846266925335, 0.004758830647915602, 0.08407192677259445, 0.7939804196357727]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4724631905555725, 0.5275368094444275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3704957365989685, 0.29741764068603516, 0.33208662271499634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3550415635108948, 0.23895421624183655, 0.1918220818042755, 0.21418219804763794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32254743576049805, 0.24052399396896362, 0.16188018023967743, 0.12995028495788574, 0.14509814977645874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15017758309841156, 0.15153159201145172, 0.16940639913082123, 0.19766293466091156, 0.219414621591568, 0.11180687695741653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015182464267127216, 0.00015647878171876073, 0.000142706063343212, 0.0001157206206698902, 9.032258822117001e-05, 0.9977854490280151, 0.001557365758344531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.4290164219564758e-05, 2.9549921237048693e-05, 3.5497294447850436e-05, 3.618533446569927e-05, 3.0238359613576904e-05, 0.9985929131507874, 0.00012786565639544278, 0.0011234765406697989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021904677851125598, 0.00021927020861767232, 0.00022306352911982685, 0.0002232459228252992, 0.00021709314023610204, 0.994728147983551, 0.000926846347283572, 0.0014565099263563752, 0.0017868317663669586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.368025060510263e-05, 6.06044486630708e-05, 6.0061462136218324e-05, 6.162714271340519e-05, 6.331521581159905e-05, 0.9958090782165527, 0.0003948681696783751, 0.0012508357176557183, 0.001082087866961956, 0.0011538660619407892, 0.0, 0.0, 0.0, 0.0, 0.0], [6.727999425493181e-05, 6.095254866522737e-05, 5.470800169860013e-05, 5.393477840698324e-05, 5.932519707130268e-05, 0.997840166091919, 0.00022321469441521913, 0.0005773219163529575, 0.0002463585406076163, 0.0003829844354186207, 0.00043366814497858286, 0.0, 0.0, 0.0, 0.0], [4.951675873599015e-05, 4.574684498948045e-05, 4.332248863647692e-05, 4.461448043002747e-05, 4.9320700782118365e-05, 0.9934147596359253, 0.000660713529214263, 0.0012994813732802868, 0.0013018277240917087, 0.001068056095391512, 0.0013095603790134192, 0.0007130288286134601, 0.0, 0.0, 0.0], [4.397597149363719e-05, 4.2640251194825396e-05, 3.800380727625452e-05, 3.378958717803471e-05, 3.2979194656945765e-05, 0.9920824766159058, 0.00045179951121099293, 0.0021719399373978376, 0.0004633906646631658, 0.001436554710380733, 0.0010938626946881413, 0.0003629741258919239, 0.001745656249113381, 0.0, 0.0], [4.628626356861787e-06, 4.707097559730755e-06, 4.483605152927339e-06, 4.002557489002356e-06, 3.568194188119378e-06, 0.9984585046768188, 0.0001402992056682706, 0.0001846294035203755, 0.000188569538295269, 0.00025754081434570253, 0.00028369450592435896, 4.209345206618309e-05, 0.00031779942219145596, 0.00010555058543104678, 0.0], [2.907429006882012e-06, 3.016140453837579e-06, 3.1629444947611773e-06, 3.159899279125966e-06, 2.977415761051816e-06, 0.9992831349372864, 5.266232983558439e-05, 5.253015842754394e-05, 0.00010882446804316714, 9.827253234107047e-05, 9.90591652225703e-05, 2.5150509827653877e-05, 0.00011208422074560076, 4.9864069296745583e-05, 0.00010311305231880397]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5093567371368408, 0.49064329266548157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23512223362922668, 0.38959529995918274, 0.3752824664115906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.102333664894104, 0.21106137335300446, 0.3497270941734314, 0.33687788248062134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05884764716029167, 0.09631168097257614, 0.19864150881767273, 0.329146146774292, 0.3170529901981354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12444642186164856, 0.12681861221790314, 0.1271420419216156, 0.12293461710214615, 0.11584261804819107, 0.3828156888484955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043867550790309906, 0.03862560912966728, 0.04006019979715347, 0.04906117171049118, 0.06311991065740585, 0.7470679879188538, 0.01819753646850586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010630412958562374, 0.00796618964523077, 0.007630160078406334, 0.009693924337625504, 0.013288467191159725, 0.8082076907157898, 0.013673276640474796, 0.12890996038913727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005250878166407347, 0.004727485589683056, 0.0038394432049244642, 0.0033201007172465324, 0.0035659486893564463, 0.9553226828575134, 0.005242707207798958, 0.01669984869658947, 0.0020308825187385082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012170640984550118, 0.0011759947519749403, 0.001048248610459268, 0.0009356901864521205, 0.0009309665183536708, 0.976889431476593, 0.002096982207149267, 0.013796312734484673, 0.0009380843257531524, 0.0009711409220471978, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0026948656886816025, 0.003193275071680546, 0.0032594879157841206, 0.0027054387610405684, 0.0020331372506916523, 0.8750705122947693, 0.0006304297130554914, 0.10632722824811935, 0.0004495689645409584, 0.001232785638421774, 0.0024032089859247208, 0.0, 0.0, 0.0, 0.0], [0.0020992818754166365, 0.0023243380710482597, 0.002543970011174679, 0.0025979159399867058, 0.002438151743263006, 0.9759296178817749, 0.0013577865902334452, 0.007701313588768244, 0.0007109447033144534, 0.0008699273457750678, 0.00103422359097749, 0.00039246573578566313, 0.0, 0.0, 0.0], [0.0006645857938565314, 0.000825223105493933, 0.001153052900917828, 0.0013731758808717132, 0.0012314445339143276, 0.9414350390434265, 0.0009024326573126018, 0.03716186061501503, 0.0004279616696294397, 0.0006692471797578037, 0.0018645658856257796, 7.052319415379316e-05, 0.0122209582477808, 0.0, 0.0], [0.00057365553220734, 0.0006018690764904022, 0.0006537474691867828, 0.0007280175923369825, 0.0007970486185513437, 0.9882931113243103, 0.0006075051496736705, 0.0036741886287927628, 0.00016629535821266472, 0.00014176704280544072, 0.00047405724762938917, 4.564652044791728e-05, 0.0007403886411339045, 0.002502700313925743, 0.0], [0.0006039770087227225, 0.0005522497813217342, 0.0005515625816769898, 0.0006097284494899213, 0.0007131096790544689, 0.9948691129684448, 0.0006476752460002899, 0.0003019798605237156, 0.00010658930841600522, 7.721433212282136e-05, 0.00010831691906787455, 4.095850817975588e-05, 0.00015153427375480533, 0.0005855712806805968, 8.04471637820825e-05]]], \"attentionHeadNames\": [\"L17H7\", \"L1H0\", \"L1H7\"], \"tokens\": [\"<bos>\", \"Is\", \" Paris\", \" the\", \" largest\", \" city\", \" in\", \" Germany\", \"?\", \"\\n\"]}\n",
       "    )\n",
       "    </script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.attention_analysis import visualize_attention_patterns\n",
    "from IPython.display import HTML\n",
    "\n",
    "positive_html = visualize_attention_patterns(\n",
    "    model,\n",
    "    top_positive_logit_attr_heads,\n",
    "    cache,\n",
    "    df,\n",
    "    batch_index,\n",
    "    f\"Top {top_k} Positive Logit Attribution Heads\",\n",
    ")\n",
    "\n",
    "negative_html = visualize_attention_patterns(\n",
    "    model,\n",
    "    top_negative_logit_attr_heads,\n",
    "    cache,\n",
    "    df,\n",
    "    batch_index,\n",
    "    title=f\"Top {top_k} Negative Logit Attribution Heads\",\n",
    ")\n",
    "\n",
    "HTML(positive_html + negative_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation patching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get into activation patching. First, we need some corrupted prompts as a baseline for our path patching algorithm. The choice of the corrupted prompts is quite delicate and fundamental for path patching to help narrow-down the components part of the circuit in question. We want our corrupted examples to only differ in the aspect we are testing such that, when the model performs significantly better with some paths exchanged with the clean activations, we can be sure the components attached to this paths are most likely part of the circuit. It is also important to change as little tokens as possible to not change the nature of the task. In our case, there are two intuitive solutons. <br>\n",
    "\n",
    "Let's, again, consider the example: <br>\n",
    "> Is Paris the capital of France?\n",
    "\n",
    "Grammatically, we are looking at a subject-verb inversion which means the subject and verb of a sentence (Paris is the captibal of France.) have been interchanged to form a question. 'Is' is the verb that hints a question, 'Paris' is the subject, and 'the capital' is a noun phrase complementing the subject and 'of France' is modifyin the noun phrase. \n",
    "While the grammatical point of view might be helpful for some more technical tasks, such as indirect object identification, I feel like in our case it is simpler to try to think what we want to test for. We want to test if the model is able to query it's factual knowledge to recognize that Paris is indeed the capital of France and subsequently return a token confirming this. Coming from that angle, what parts of the sentence are essential to the task? As human, how do we query our brain for the answer to this question?\n",
    "Before we get into an algorithm that could be used for this task, there is a fundamental questions to answer. How is the factual knowledge stored in transformers? Coming from the world of computers, there are two answers: relational and non-relational databases. Relational databases save data in a table-format where objects (rows) with different attributes (columns) are described. Non-relational databases do no not follow this structured approach. Prominent examples are key-value storages and graph databases. Neuroscientists provide evidence that the human brain falls rather in this latter category of non-relational databases where neurons that [\"fire together, wire together\"](https://www.brainfacts.org/thinking-sensing-and-behaving/learning-and-memory/2021/what-memories-are-made-of-100121) capturing information about related bits of information. While I am not going to claim to know what happens in the human brain, I find the idea of the hyppocampus being a big graph of knowledge points whose connection captures relationships between the bits of information very intriging. Since neural networks are heavily inspired by the human brain, let's consider an algorithm how a neural network saving information in Graph like structure could solve the factual knowledge retrieval task at hand:\n",
    "1. Recognize question: A form of to be in present tense in the beginning of the sentence pretty much always suggest a question following. The question mark at the end confirms this. This should hint that the answer should encompass that the following statement is either True or False, hence narrowing down the set of possible tokens to True- and False-Tokens.\n",
    "2. What is the statement? The statemnt is \"Paris is the captial of France\". This could be modelled as a graph with the nodes \"Paris\" and \"France\" connected by the edge/relationship \"capital\". Note that this is a big assumption. The network could model this relationship completely differenc (key-valu,...) or not at all. Here, I would just like to go through an example algorithm end-to-end to find suitable tokens to replace for the corrupted prompt.\n",
    "3. Is the statement correct? Now comes the tricky part. How does the model check if the statement is correct. In our case it would simply have to check if the nodes Paris and France are connected by the edge \"capital\". This graph like structure could for instance be encoded in the embedding space where the embeddings of Paris and France are \"connected\" via similar values in a privileged basis which represents the feature \"capital\".\n",
    "4. Write output to individual stream: Finally, the circuite should alter the residual stream such that the logits and thus, the probability of the predicted outcome (True/False) are increased.\n",
    "\n",
    "This is all well and good but what does this tell us for the corrupted prompt? Assuming Paris and France are detected as keys and their relationship is to be examined, we could alter either one of the keys or the relationship. Since we want to explore factual knowledge around Paris, let's rull this option out. It remains the option to remove either the second key or the realtionship. I do not see a clear benefit for either option, so let's just start with option 1, altering the second key, and come back to the alternative solutiosn if this does not yield valuable insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Paris the capital of France?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Paris the capital of France?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the Eiffel Tower located in Paris?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Paris known as the City of Light?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the Louvre Museum in Rome?\\n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Is the official language of Paris English?\\n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is Montmartre a district in Paris?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Does Paris have a desert climate?\\n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is the Seine River in Paris?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Is the Mona Lisa displayed in Paris?\\n</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question  answer\n",
       "0             Is Paris the capital of France?\\n    True\n",
       "1             Is Paris the capital of France?\\n    True\n",
       "2       Is the Eiffel Tower located in Paris?\\n    True\n",
       "3        Is Paris known as the City of Light?\\n    True\n",
       "4               Is the Louvre Museum in Rome?\\n   False\n",
       "5  Is the official language of Paris English?\\n   False\n",
       "6          Is Montmartre a district in Paris?\\n    True\n",
       "7           Does Paris have a desert climate?\\n   False\n",
       "8                Is the Seine River in Paris?\\n    True\n",
       "9        Is the Mona Lisa displayed in Paris?\\n    True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Is Paris the capital of France?\\n',\n",
       "       'Is Paris the capital of France?\\n',\n",
       "       'Is the Eiffel Tower located in Paris?\\n',\n",
       "       'Is Paris known as the City of Light?\\n',\n",
       "       'Is the Louvre Museum in Rome?\\n',\n",
       "       'Is the official language of Paris English?\\n',\n",
       "       'Is Montmartre a district in Paris?\\n',\n",
       "       'Does Paris have a desert climate?\\n',\n",
       "       'Is the Seine River in Paris?\\n',\n",
       "       'Is the Mona Lisa displayed in Paris?\\n'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"question\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_prompt = {\n",
    "    \"corrupted_question\": [\n",
    "        'Is Paris the capital of UK?\\n',\n",
    "        'Is Paris the capital of UK?\\n',\n",
    "        'Is the Eiffel Tower located in Paris?\\n',\n",
    "        'Is Paris known as the City of Dark?\\n',\n",
    "        'Is the Louvre Museum in Rome?\\n',\n",
    "        'Is the official language of Paris English?\\n',\n",
    "        'Is Montmartre a district in Paris?\\n',\n",
    "        'Does Paris have a desert climate?\\n',\n",
    "        'Is the Seine River in Paris?\\n',\n",
    "        'Is the Mona Lisa displayed in Paris?\\n'\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FK-in-MI",
   "language": "python",
   "name": "fk-in-mi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
